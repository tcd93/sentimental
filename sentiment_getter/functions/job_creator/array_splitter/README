# Array Splitter Lambda Function

This Rust AWS Lambda function splits large arrays into smaller chunks to avoid timeouts in downstream processing.

## Purpose

The function is used within the sentiment analysis pipeline to split large batches of social media posts into manageable chunks. This prevents timeouts when creating sentiment analysis jobs and ensures reliable processing.

## Implementation Details

- Written in Rust for performance and memory safety
- Takes an array of post IDs as input
- Splits the input array into two roughly equal chunks
- Returns a JSON object with `chunk1` and `chunk2` arrays

## Building

To build the deployment package (split_result.zip) using Docker:

1. Build the Docker image for compilation:
   ```bash
   docker build -t split-result-builder .
   ```

2. Create a container and extract the built artifact:
   ```bash
   docker create --name extract split-result-builder
   docker cp extract:/package/split_result.zip .
   docker rm extract
   ```

3. The resulting `split_result.zip` file contains the Lambda deployment package

## Deployment

When deploying with AWS SAM or CloudFormation:

1. Ensure the target directory is excluded from packaging:
   ```
   # .gitignore in project root
   **/target/
   ```

2. Reference the zip file directly in your template:
   ```yaml
   SplitResultFunctionName:
     Type: AWS::Serverless::Function
     Properties:
       PackageType: Zip
       CodeUri: path/to/split_result.zip
       Handler: bootstrap
       Runtime: provided.al2
   ```

## Testing

Run tests using:
```bash
cargo test
```

Example input:
```json
["id1", "id2", "id3", "id4", "id5"]
```

Example output:
```json
{
  "chunk1": ["id1", "id2"],
  "chunk2": ["id3", "id4", "id5"]
}
```

## Development Notes

- The function is optimized for small binary size using Rust build optimizations
- The multi-stage Docker build ensures minimal deployment package size
- For local development without Docker, you'll need the `x86_64-unknown-linux-musl` target installed